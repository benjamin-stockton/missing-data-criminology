---
title: "Sentencing Analysis with Pattern Mixture Modeling"
author: 
    - name: C. Clare Strange
      email: cs3846@drexel.edu
      affiliations:
          - name: Department of Criminology and Justice Studies, Drexel University
    - name: Benjamin Stockton
      email: benjamin.stockton@uconn.edu
      orcid: 0000-0002-3820-5293
      affiliations: 
          - name: Department of Statistics, University of Connecticut
    - name: Ofer Harel
      affiliations: 
          - name: Department of Statistics, University of Connecticut
date: today
number-sections: true 
number-depth: 2
toc: false
format:
  pdf:
    keep-tex: true
execute: 
  cache: true
  echo: false
  warning: false
bibliography: ../Literature/Criminology.bib
fig-height: 5
fig-width: 8
abstract: ""
keywords: incomplete data, pattern-mixture model
editor: visual
---

```{r}
#| label: set-up
library(dplyr, warn.conflicts = FALSE, quietly = TRUE)
library(ggplot2, warn.conflicts = FALSE, quietly = TRUE)
library(mice, warn.conflicts = FALSE, quietly = TRUE)
library(GLMMadaptive)
library(broom.mixed)
library(brms)
library(VIM)
library(bayesplot)

theme_set(theme_bw())
color_scheme_set("brightblue")
```

## Methods

We propose using a combination of multiple imputation and pattern-mixture models to perform sensitivity analyses for the race effect estimates from a lognormal hurdle model used to predict the sentence length as a response variable under incompleteness of the race variable. The lognormal hurdle model can be used to model complex data where the dependent variable is a combination of true zeros and a continuous distribution for non-zero observations. Sentence length is one such instance wherein this phenomena arises with offenders sentenced to a community sentence or parole receive a sentence of 0 days ($Y^* = 0$ months) while offenders sentenced to jail or prison time receive a sentence of $Y > 0$ days ($Y^* = Y/30$ months).

The class of hurdle models fits a logistic regression model to the zero part of the data and then fits a count or continuous generalized linear model to the non-zero part of the data. The coefficients from each part of the model can be interpreted independently or marginally. Predictions are made from the mixture of the zero and non-zero components.

The incomplete data analysis is performed in the multiple imputation framework [@rubinMultipleImputationNonresponse1987]. In this set-up the incomplete variables are imputed or filled in $M$ times using draws from a predictive distribution using a regression model. The imputations are then used to create $M$ completed data sets that are then analyzed separately using a standard complete data method, such as a hurdle regression model. The estimates from each of the $M$ model fits are combined using Rubin's rules. In particular, we are going to use random forests [@wrightrangerAFastImplementation2017] to perform the imputations in the multiple imputation by chained equations framework [@raghunathan2001, @buuren2010mice].

Pattern-mixture models can be used in conjunction with multiple imputation to perform a sensitivity analysis for the model of interest to particular perturbations of the distribution from which the imputations are drawn. This allows us to investigate the impacts nonignorable missingness could potentially have on our analysis.

## Analysis

```{r}
#| label: load-data
df <- readr::read_csv("../Data/PCS-most-serious-sentence-2010-2019-pmm.csv",
                      show_col_types = FALSE)

df <- df |> mutate(
        YEAR = as.factor(YEAR),
        INCAR = case_when(
            JP_MIN == 0 ~ 0,
            JP_MIN > 0 ~ 1,
            TRUE ~ NA
        ),
        SEX = case_when(
            MALE == 1 ~ "Male",
            MALE == 0 ~ "Female",
            TRUE ~ NA
        ),
        OFF_RACE = case_when(
            OFF_RACER == 1 ~ "WHITE",
            OFF_RACER == 2 ~ "BLACK",
            OFF_RACER == 3 ~ "LATINO",
            OFF_RACER == 4 ~ "OTHER",
            TRUE ~ NA
        ),
        PRVREC = case_when(
            PRSR == 0 ~ "0",
            PRSR == 1 ~ "1/2/3",
            PRSR == 2 ~ "4/5",
            PRSR == 3 ~ "REVOC/RFEL",
            TRUE ~ NA
        ),
        CRIME = case_when(
            CRIMETYPE == 1 ~ "Persons",
            CRIMETYPE == 2 ~ "Property",
            CRIMETYPE == 3 ~ "Drug",
            CRIMETYPE == 4 ~ "DUI",
            CRIMETYPE == 5 ~ "Other",
            TRUE ~ NA
        )
    ) |>
    select(
        -c(OFF_RACER, PRSR, MALE, CRIMETYPE)
    )

df$OFF_RACE <- factor(df$OFF_RACE, levels = c("WHITE", "BLACK", "LATINO", "OTHER"))
```

```{r}
#| label: fig-miss-pattern
#| fig-cap: Missing data patterns for the full data set.
df |> 
    select(
        JP_MIN, OFF_RACE, DOSAGE, RECMIN, PRVREC, CRIME, TRIAL, SEX
    ) |> 
    aggr(sortby = "JP_MIN", plot = FALSE) |>
    plot(numbers = TRUE, prop = FALSE)
```

```{r}
#| label: tbl-yearly-summary
#| tbl-cap: Summary statistics on sentence length (days) and incarceration.
#| 
df |>
    # filter(JP_MIN > 0) |>
    group_by(YEAR) |>
    summarize(
        mean_JP_MIN = mean(JP_MIN, na.rm = TRUE),
        sd_JP_MIN = sd(JP_MIN, na.rm = TRUE),
        min_JP_MIN = min(JP_MIN, na.rm = TRUE),
        median_JP_MIN = median(JP_MIN, na.rm = TRUE),
        max_JP_MIN = max(JP_MIN, na.rm = TRUE),
        p_INCAR = mean(INCAR, na.rm = TRUE)
    ) |>
    kableExtra::kable(format = "latex", digits = 2, escape = TRUE,
                      col.names = c("Year", "Mean", "SD", "Median", "Min.", "Max.", "P(Incar)"),
                      booktabs = TRUE, padding = 0)
```

```{r}
#| label: fig-sen-len-yearly
#| fig-cap: Density plots for A) Sentence length (day) by year. B) Log sentence lengths (day) plus one day by year.

p1 <- df |>
    # filter(JP_MIN > 0) |>
    ggplot(aes(YEAR, JP_MIN)) +
    geom_violin(draw_quantiles = c(0.025, 0.25, 0.5, 0.75, 0.975)) +
        facet_wrap(YEAR~., scales = "free", nrow = 5) +
    coord_flip() +
    labs(x = "") +
    theme(axis.text.y = element_blank(),
          axis.ticks.y = element_blank())
p2 <- df |>
    # filter(JP_MIN > 0) |>
    ggplot(aes(YEAR, log1p(JP_MIN))) +
    geom_violin(draw_quantiles = c(0.025, 0.25, 0.5, 0.75, 0.975)) +
        facet_wrap(YEAR~., scales = "free", nrow = 5) +
    coord_flip() +
    labs(x = "") +
    theme(axis.text.y = element_blank(),
          axis.ticks.y = element_blank())

cowplot::plot_grid(p1, p2, nrow = 1, labels = "AUTO")
```

```{r}
#| label: fig-sen-len-crime
#| fig-cap: A) Sentence length (day) by most serious crime type. B) Log of sentence length plus one day by most serious crime type.
#| fig-height: 4

p1 <- ggplot(df, aes(CRIME, JP_MIN)) +
    geom_violin(draw_quantiles = c(0.025, 0.25, 0.5, 0.75, 0.975)) +
    geom_point(size = 0.5)

p2 <- ggplot(df, aes(CRIME, log(JP_MIN))) +
    geom_violin(draw_quantiles = c(0.025, 0.25, 0.5, 0.75, 0.975)) +
    geom_point(size = 0.5)

cowplot::plot_grid(p1, p2, nrow = 1, labels = "AUTO")
```

```{r}
#| label: fig-sen-len-race
#| fig-cap: A) Sentence length by offender race. B) Log of sentence length (plus one day)
#| fig-height: 4
p1 <- ggplot(df, aes(OFF_RACE, JP_MIN)) +
    geom_violin(draw_quantiles = c(0.025, 0.25, 0.5, 0.75, 0.975)) +
    geom_point(size = 0.5, shape = 1)

p2 <- ggplot(df, aes(OFF_RACE, log(JP_MIN))) +
    geom_violin(draw_quantiles = c(0.025, 0.25, 0.5, 0.75, 0.975)) +
    geom_point(size = 0.5, shape = 1)

cowplot::plot_grid(p1, p2, nrow = 1, labels = "AUTO")
```

```{r}
#| label: fig-incar-cime
#| fig-cap: Incarceration decision by most serious crime type. INCAR == 1 indicates incarceration. INCAR == 0 indicates parole.
#| fig-height: 4
ggplot(df, aes(as.factor(INCAR), fill = CRIME)) +
    geom_bar(position = "dodge")
```

```{r}
#| label: fig-sen-len-qq
#| layout-ncol: 2
#| fig-cap: QQ plots of the sentence length (days)
#| fig-subcap: 
#|   - Sentence length in days
#|   - Log of sentence length plus one day
sent_non0 <- df$JP_MIN[which(df$INCAR == 1)]
s <- sample(length(sent_non0), size = 10000, replace = FALSE)

qqnorm(sent_non0[s])
qqline(sent_non0[s])

qqnorm(log1p(sent_non0[s]))
qqline(log1p(sent_non0[s]))
```

```{r}
#| label: fig-scatter-pairs
#| fig-cap: Scatter plot matrix of the numeric predictors and the log plus one of the sentence length (days).
df[s,] |> 
    mutate(jp_min_l1p = log1p(JP_MIN)) |>
    select(DOSAGE, DOSAGEQ, OGS, OGSQ, TRIAL, RECMIN, jp_min_l1p) |>
    GGally::ggpairs()
```

```{r}
#| label: fig-fluxplot
#| include: false
fluxplot(df)
```

### Multiple Imputation

I'll prepare the data for analysis next. First, I'll center and scale the numeric predictors which are Offense Gravity Score (OGS), defendant age, and the square of each. Then I'll use MICE to multiply impute the incomplete variables with random forest. For now I'll use $M = 10$ since less than 5% of all observations are missing (mainly in defendant race). The number of imputations to use should be informed by the amount of missing information due to incompleteness for each variable [@harelInferencesMissingInformation2007].

```{r}
#| label: mice
#| eval: false
df[,c("OGS", "OGSQ", "DOSAGE", "DOSAGEQ")] <- scale(df[,c("OGS", "OGSQ", "DOSAGE", "DOSAGEQ")], center = TRUE, scale = TRUE)

df[,"DOSAGEQ"] <- df[,"DOSAGE"]^2
df[,"OGSQ"] <- df[,"OGS"]^2

imps0 <- mice(df[s,], m = 1, method = "rf", maxit = 0)

mthd <- imps0$method
mthd["JP_MIN_MON"] <-  "~I(JP_MIN / 30)"
mthd["INCAR"] <- "~I(ifelse(JP_MIN > 0, 1, 0))"
# mthd[c("RECMIN", "INCAR", "OFF_RACE", "PRVREC")] <- "cart"
mthd

pred_mat <- imps0$predictorMatrix
pred_mat[,"JPR_ID"] <- 0
pred_mat

imps <- mice(df[s,], m = 5, method = mthd, predictorMatrix = pred_mat, maxit = 10)

plot(imps)

saveRDS(imps, "fits/mice-rf-subsample.rds")
```

```{r}
#| label: load-mice
#| echo: false

imps <- readRDS("fits/mice-rf-subsample.rds")
```

### Logistic Regression on Incarceration

I'll fit a logistic regression like before as a sanity check. The estimated odds ratio for increased odds of incarceration for a Black defendant over a White defendant should be roughly 1.25 as we saw in the complete case analysis in the previous paper.

```{r}
#| label: mice-glm
#| eval: false
fit_incar <- with(imps, glm(INCAR ~ DOSAGE + DOSAGEQ + SEX*OFF_RACE + OGS + OGSQ +
                      OGS * PRVREC + PRVREC + RECMIN + CRIME + TRIAL +
                     as.factor(YEAR) + as.factor(COUNTY),
                 family = binomial(link = "logit"),
                 x = FALSE, y = FALSE,
                 model = FALSE))
saveRDS(fit_incar, "fits/fit-glm-logit-incar.rds")
```

```{r}
#| label: tbl-glm-summary
#| tbl-cap: Summary of the logistic regression fit for predicting sentencing decision (In/Out) excluding the year and county estimates for brevity.

fit_incar <- readRDS("fits/fit-glm-logit-incar.rds")
smry <- summary(pool(fit_incar))

smry |>
    filter(stringr::str_sub(term, 1,3) != "as.") |>
    mutate(
        lb95 = estimate - qt(0.975, df = df) * std.error,
        ub95 = estimate + qt(0.975, df = df) * std.error,
        sig = case_when(
            lb95 > 0 ~ "*",
            ub95 < 0 ~ "*",
            TRUE ~ ""
        )
    ) |>
    select(term, estimate, std.error, lb95, ub95, sig) |>
    kableExtra::kable(format = "latex", digits = 2, escape = TRUE,
                      col.names = c("Term", "Estimate", "SE", "LB 95% CI", "UB 95% CI", "Sig."),
                      booktabs = TRUE)
```

```{r}
#| label: log-reg-avg
#| eval: false
#| include: false
avg_data <- df[s,] |>
    group_by(SEX, OFF_RACE) |>
    summarize(
        DOSAGE = mean(DOSAGE, na.rm = TRUE),
        DOSAGEQ = mean(DOSAGEQ, na.rm = TRUE),
        OGS = mean(OGS, na.rm = TRUE),
        OGSQ = mean(OGSQ, na.rm = TRUE),
        `PRVREC1/2/3` = mean(PRVREC == "1/2/3", na.rm = TRUE),
        `PRVREC4/5` = mean(PRVREC == "4/5", na.rm = TRUE),
        `PRVRECREVOC/RFEL` = mean(PRVREC == "REVOC/RFEL", na.rm = TRUE),
        RECMIN = mean(RECMIN, na.rm = TRUE),
        CRIMEDUI = mean(CRIME == "DUI"),
        CRIMEOther = mean(CRIME == "Other"),
        CRIMEPersons = mean(CRIME == "Persons"),
        CRIMEProperty = mean(CRIME == "Property"),
        TRIAL = mean(TRIAL)
    ) |>
    filter(!is.na(OFF_RACE)) |>
    ungroup() |>
    mutate(
        OFF_RACEBLACK = case_when(OFF_RACE == "BLACK" ~ 1, TRUE ~ 0),
        OFF_RACELATINO = case_when(OFF_RACE == "LATINO" ~ 1, TRUE ~ 0),
        OFF_RACEOTHER = case_when(OFF_RACE == "OTHER" ~ 1, TRUE ~ 0),
        SEXMale = case_when(SEX == "Male" ~ 1, TRUE ~ 0)
    ) |>
    select(DOSAGE, DOSAGEQ, SEXMale, OFF_RACEBLACK, OFF_RACELATINO, OFF_RACEOTHER, OGS, 
           OGSQ, `PRVREC1/2/3`, `PRVREC4/5`, `PRVRECREVOC/RFEL`, RECMIN, 
           CRIMEDUI, CRIMEOther, CRIMEPersons, CRIMEProperty, TRIAL) |>
    mutate(
        `SEXMale:OFF_RACEBLACK` = SEXMale * OFF_RACEBLACK,
        `SEXMale:OFF_RACELATINO` = SEXMale * OFF_RACELATINO,
        `SEXMale:OFF_RACEOTHER` = SEXMale * OFF_RACEOTHER,
        `OGS:PRVREC1/2/3` = OGS * `PRVREC1/2/3`,
        `OGS:PRVREC4/5` = OGS * `PRVREC4/5`,
        `OGS:PRVRECREVOC/RFEL` = OGS * `PRVRECREVOC/RFEL`
    )

betas <- smry$estimate
names(betas) <- smry$term

pred_probs <- cbind(rep(1, 8), as.matrix(avg_data)) %*% betas
pred_probs <- (1 + exp(-pred_probs))^-1
names(pred_probs) <- c("FW", "FB", "FL", "FO", "MW", "MB", "ML", "MO")

ps <- prop.table(table(df$SEX[s], df$OFF_RACE[s]))

P_B <- ps[2,2] / sum(ps[,2]) * pred_probs["MB"] + ps[1,2] / sum(ps[,2]) * pred_probs["FB"]
P_W <- ps[2,1] / sum(ps[,1]) * pred_probs["MW"] + ps[1,1] / sum(ps[,1]) * pred_probs["FW"]

(P_B / (1 - P_B))  / ((P_W) / (1 - P_W))
```

From the logistic regression fit with MI and $M = 10$ imputations done using predictive mean matching, we found that a Black defendant is `r round(exp(0.2225), 2)` (95% CI of (`r round(exp(0.2225 - 1.96 * 0.0064), 3)`, `r round(exp(0.2225 + 1.96 * 0.0064), 3)`) times more likely to be sentenced to incarceration than an otherwise similar White defendant.

We re-analyze the data using a generalized linear mixed model and again taking the binary incarceration decision as the outcome and random effects for the Year and County with random slopes for the most serious Crime type by County.

```{r}
#| label: mice-glmm
#| eval: false
fit_incar_mm <- with(imps, lme4::glmer(INCAR ~ DOSAGE + DOSAGEQ + SEX*OFF_RACE + OGS + OGSQ +
                     PRVREC + OGS * PRVREC + RECMIN + CRIME + TRIAL +
                     (1 | YEAR) + (1 | COUNTY),
                 family = binomial(link = "logit"),
                 verbose = 0))

# c_dat <- complete(imps, "all")
# fit_list <- parallel::mclapply(c_dat, 
#                                mc.cores = 10,
#                                function(d1) {
#                  
#                  fit <- lme4::glmer(INCAR ~ DOSAGE + DOSAGEQ + SEX*OFF_RACE + OGS + OGSQ +
#                              PRVREC + RECMIN + CRIME + TRIAL +
#                              (1 | YEAR) + (1 + CRIME | COUNTY),
#                              data = d1,
#                              family = binomial(link = "logit"),
#                              verbose = 0)
#                  return(fit)
#               })
# 
# fit_incar_mm <- as.mira(fit_list)
saveRDS(fit_incar_mm, "fits/fit-glmm-logit-incar.rds")
```

```{r}
#| label: tbl-glmm-sum
#| tbl-cap: Summary statistics for the fixed effects from the logistic regression mixed model.
fit_incar_mm <- readRDS("fits/fit-glmm-logit-incar.rds")

smry <- summary(pool(fit_incar_mm))
smry |>
    mutate(
        se = std.error,
        lb95 = estimate - qt(0.975, df = df) * se,
        ub95 = estimate + qt(0.975, df = df) * se,
        sig = case_when(
            lb95 > 0 ~ "*",
            ub95 < 0 ~ "*",
            TRUE ~ ""
        )
    ) |>
    select(
        term, estimate, se, lb95, ub95, sig
    ) |>
    kableExtra::kable(format = "latex", digits = 2, escape = TRUE,
                      col.names = c("Term", "Estimate", "SE", "LB 95% CI", "UB 95% CI", "Sig."),
                      booktabs = TRUE)
```

### Hurdle Models

A hurdle model models data with a high number of zeros (compared to standard distributions). The model places a probability point mass $P(Y = 0) = \theta$ at $Y = 0$ and uses a truncated (at zero) probability distribution for the non-zero sample space $P(Y \neq 0) = p_{y \neq 0}(y)$. This differs from a zero-inflated model which is a mixture of two distributions (includes the non-zero distribution's zero probability) as the hurdle model truncates the non-zero distribution.

I'll create a GLM with brms and the log normal hurdle distribution.

The model is composed of two components: the hurdle for the zeros and the GLM for the non-zero part. Let $\pi_i$ be the probability that the $i$th observation is zero and $P(Y_i \neq 0) = f_{y\neq 0}(y-i)$ where $f_{y\neq 0}$ is a truncated probability mass/density function.

#### Lognormal Hurdle GLM with Intercept-only Hurdle

Under this first model, we will model the probability of $Y_i = 0$ as constant across the observations using an intercept-only model; the default for `brms` [@b√ºrkner2017].

$$
\mathrm{logit}^{-1}(P(Y_i = 0)) = \pi_0
$$ {#eq-hurdle-intercept}

$$
\log(Y_i) = \mathbf{x}_i \boldsymbol{\beta} + \mathbf{z}_i \mathbf{u} + \epsilon_i
$$ {#eq-hurdle-glm} where $\mathbf{u}$ is MVN with $E(\mathbf{U}) = 0$ and covariance matrix $Cov(\mathbf{U}) = G$, $\epsilon_i \overset{iid}{\sim} N(0, \sigma^2)$ and $\mathbf{u}$ and $\boldsymbol{\epsilon}$ are mutually independent. $\mathbf{x}_i$ and $\mathbf{z}_i$ are rows from two known design matrices for the population-level and group-level effects respectively.

The model is specified as usual for a GLMM:

```         
brm(JP_MIN ~ DOSAGE + DOSAGEQ + SEX*OFF_RACE + OGS + OGSQ +
                     PRVREC + RECMIN + CRIME + TRIAL +
                     (1 | YEAR) + (1 + CRIME |COUNTY),
               data = data,
               family = hurdle_lognormal(link = "identity",
                           link_sigma = "log",
                           link_hu = "logit"))
```

Here we include group-level effects for the year, the county, and the crime-type in the county in case the judicial system sentences the different crime-types differently relative to other counties. Each of the population-level regression coefficients are given a normal prior $\beta_j \sim N(0, 25).$ The group-level effects for the intercepts and effects for crime-type are given noncentral t-distributions $\gamma_k \sim t_{3; 0, 2.5}$ while the correlations between the county-level crime-type effects and county-level intercepts are given $\rho_{i.j} \sim lkj(1)$ priors. The hurdle parameter gets a $U(0,1)$ prior. The error term's variance also gets a noncentral t prior $\sigma \sim t_{3; 0, 2.5}.$

The quantity of interest is the regression coefficient for race.

```{r}
#| label: brms-hurdle-model-prior1
#| echo: false
#| results: hide

library(brms)

bprior <- get_prior(JP_MIN ~ DOSAGE + DOSAGEQ + SEX*OFF_RACE + OGS + OGSQ +
                     PRVREC + OGS * PRVREC + RECMIN + CRIME + TRIAL +
                     (1 | YEAR) + (1 |COUNTY),
               data = df[s,],
               family = hurdle_lognormal(link = "identity", link_sigma = "log", link_hu = "logit"))

bprior$prior[1] <- "normal(0, 25)"
bprior
```

```{r}
#| label: brms-hurdle-model
#| eval: false
#| results: hide

# library(future)
# plan(multicore, workers = 10)
fit_brm <- brm_multiple(JP_MIN ~ DOSAGE + DOSAGEQ + SEX*OFF_RACE + OGS + OGSQ +
                     PRVREC + OGS * PRVREC + RECMIN + CRIME + TRIAL +
                     (1 | YEAR) + (1 |COUNTY),
               data = imps,
               family = hurdle_lognormal(link = "identity", link_sigma = "log", link_hu = "logit"),
               prior = bprior,
               chains = 2, cores = 15, iter = 2000, refresh = 100,
               # file = "brms_fit/brms-hurlde-si-fit",
               # file_refit = "on_change",
               save_model = "stan/brms-hurdle-si.stan")

saveRDS(fit_brm, file = "fits/fit-brms-hurdle-lognormal-mi.rds")
```

```{r}
#| label: tbl-brms-hurdle-fe-int-only
#| tbl-cap: Fixed/Population-level effects for the non-zero part of the lognormal hurdle model with intercept only for the zero-part.
fit_brm <- readRDS("fits/fit-brms-hurdle-lognormal-mi.rds")

smry1 <- summary(fit_brm)
smry1$fixed |>
    select(Estimate, Est.Error, `l-95% CI`, `u-95% CI`) |>
    kableExtra::kable(format = "latex", digits = 2, escape = TRUE,
                      col.names = c("Term", "Estimate", "SE", "LB 95% CI", "UB 95% CI"),
                      booktabs = TRUE)
```

The standard deviation parameter $\sigma$ of the lognormal distribution has a posterior mean of `r round(smry1$spec_pars[1,1], 2)` (95% CI: \[`r round(smry1$spec_pars[1,3], 2)`, `r round(smry1$spec_pars[1,4], 2)` \]). The hurdle parameter has a posterior mean of `r round(smry1$spec_pars[2,1], 2)` (95% CI: \[`r round(smry1$spec_pars[2,3], 2)`, `r round(smry1$spec_pars[2,4], 2)` \]) which matches the probability of not being incarcerated in the overall population.

```{r}
#| label: brms1-vars
#| include: false
smry1$spec_pars
```

```{r}
#| label: tbl-brms1-group-eff
#| tbl-cap: Random/group-level effect standard deviation estimates for the intercept-only hurdle lognormal model.
r_effs1 <- bind_rows(smry1$random)
r_effs1$level <- c("County-level", "Year-level")
r_effs1$term <- c("sd(Intercept)", "sd(Intercept")
r_effs1 |>
    select(level, term, Estimate, `l-95% CI`, `u-95% CI`) |>
    kableExtra::kable(format = "latex", digits = 2, escape = TRUE,
                      col.names = c("Term", "Estimate", "SE", "LB 95% CI", "UB 95% CI"),
                      row.names = FALSE,
                      booktabs = TRUE)
```

```{r}
#| label: fig-hurdle-logn-mcmc
#| include: false
plot(fit_brm, ask = FALSE, N = 3)
```

From the hurdle model, we find that Black defendants do not receive different sentence lengths compared to White defendants (95% CI of (-0.11, 0.03)). In terms of 95% CIs we also find that there doesn't seem to be a difference in sentence lengths between male and female defendants either between or within each racial group.

```{r}
#| label: fig-cond-eff-brm-nonzero
#| layout-ncol: 3
#| layout-nrow: 4
#| fig-cap: Posterior estimates of the conditional effects for the lognormal glm for the non-zero-part of the intercept-only hurdle lognormal model.
#| fig-subcap: 
#|   - Age
#|   - Age Squared
#|   - Sex
#|   - Offender Race
#|   - OGS
#|   - OGS Squared
#|   - Prev. Rec.
#|   - Rec. Min. 
#|   - Crime Type
#|   - Trial
#|   - Race by Sex
#|   - OGS by Prev. Rec.

plot(conditional_effects(fit_brm), ask = FALSE)
```

```{r}
#| label: fig-cond-eff-brm1-zero
#| layout-ncol: 3
#| layout-nrow: 4
#| fig-cap: Posterior estimates of the conditional effects for the logistic regression for the zero-part of the intercept-only hurdle lognormal model.
#| fig-subcap: 
#|   - Age
#|   - Age Squared
#|   - Sex
#|   - Offender Race
#|   - OGS
#|   - OGS Squared
#|   - Prev. Rec.
#|   - Rec. Min. 
#|   - Crime Type
#|   - Trial
#|   - Race by Sex
#|   - OGS by Prev. Rec.
plot(conditional_effects(fit_brm, dpar = "hu"), ask = FALSE)
```

```{r}
#| label: fig-cond-eff-brm1-race-sex
#| include: false
#| fig-cap: Posterior estimates of conditional effects for race and sex on log sentence length. Intercept-only logistic regression for zero-part.
plot(conditional_effects(fit_brm, effects = "OFF_RACE:SEX"), ask = FALSE)
```

```{r}
#| label: fig-ppc-brm1
#| layout-ncol: 2
#| fig-cap: Posterior Predictive Checks for the intercept-only hurdle model.
#| fig-subcap: 
#|   - Density for sentence length
#|   - Density for log of sentence length plus one day
ppred1 <- posterior_predict(fit_brm)
pp_check(fit_brm, ndraws = 50) +
    coord_cartesian(xlim = c(0, 60)) + 
    labs(title = "Posterior predictive checks",
                  subtitle = "Intercept-only Hurdle",
         x = "Sentence Length (day)")

bayesplot::ppc_dens_overlay(y = log(fit_brm$data$JP_MIN),
                            yrep = log(ppred1[1:50,])) + 
    labs(title = "Posterior predictive checks",
                  subtitle = "Intercept-only Hurdle",
         x = "log(Sentence Length (day))")
```

#### Lognormal GLM Hurdle Model with Predictors on Hurdle Parameter

Next, we modify the model from the previous section to include predictors in the logistic regression part of the hurdle model @eq-hurdle-intercept. The non-zero portion @eq-hurdle-glm of the hurdle model remains the same.

$$
\mathrm{logit}^{-1}(P(Y_i=0)) = \mathbf{x}_i \boldsymbol{\alpha}.
$$

The coefficients $\boldsymbol{\alpha}$ are given normal priors $\alpha_k \overset{iid}{\sim} N(0, 10).$ The priors for the other parameters remain the same.

The new model is specified with the `bf()` function.

```         
bf(JP_MIN ~ DOSAGE + DOSAGEQ + SEX*OFF_RACE + OGS + OGSQ +
                 PRVREC + RECMIN + CRIME + TRIAL +
                 (1 | YEAR) + (1 + CRIME |COUNTY),
    hu ~ 1 + DOSAGE + DOSAGEQ + SEX * OFF_RACE + OGS + OGSQ +
            PRVREC + CRIME + TRIAL + (1 | COUNTY))
```

```{r}
#| label: inverse-gamma
#| include: false
inv_gamma_moments <- function(alpha, beta) {
    exp_1 <- beta / (alpha - 1)
    var_1 <- beta^2 / ((alpha - 1)^2 * (alpha - 2))
    return(list(mean = exp_1, var = var_1))
}

inv_gamma_moments(2.001, 1.001)
```

```{r}
#| label: brms-hurdle-model-prior2
#| echo: false
#| results: hide

bf1 <- bf(JP_MIN ~ DOSAGE + DOSAGEQ + SEX*OFF_RACE + OGS + OGSQ +
                    OGS * PRVREC + PRVREC + RECMIN + CRIME + TRIAL +
                     (1 | YEAR) + (1 |COUNTY),
          hu ~ DOSAGE + DOSAGEQ + SEX * OFF_RACE + RECMIN + OGS + OGSQ + PRVREC + CRIME + TRIAL + (1 | COUNTY))

bprior2 <- get_prior(bf1,
               data = df[s,],
               family = hurdle_lognormal(link = "identity", link_sigma = "log", link_hu = "logit"))
bprior2$class
bprior2 <- prior(normal(0, 100), class = "b") +
    prior(normal(0, 100), class = "b", dpar = "hu") +
    # prior(lkj(1), class = "cor") +
    prior(student_t(3, 0, 2.5), class = "Intercept")
    prior(inv_gamma(2.001, 1.001), class = "sd", group = "COUNTY", lb = 0) +
    prior(inv_gamma(2.001, 1.001), class = "sd", group = "YEAR", lb = 0) +
    prior(logistic(0, 1), class = "Intercept", dpar = "hu") +
    prior(inv_gamma(2.001, 1.001), class = "sd", dpar = "hu", lb = 0)

# bprior2$prior[1] <- "normal(0, 25)"
bprior2
```

Next we fit the model.

```{r}
#| label: brms-hurdle-lognormal-2
#| eval: false
#| results: hide

fit_brm2 <- brm_multiple(bf1,
               data = imps,
               family = hurdle_lognormal(link = "identity", link_sigma = "log", link_hu = "logit"),
               prior = bprior2,
               chains = 2, cores = 15, iter = 3000, refresh = 200,
               init = 0,
               control = list(adapt_delta = 0.82, max_treedepth = 10),
               # file = "brms_fit/brms-hurlde-si.fit",
               # file_refit = "on_change",
               save_model = "stan/brms-hurdle-lognormal-mi.stan")

saveRDS(fit_brm2, "fits/fit-brms-hurdle-lognormal-mi.rds")
```

```{r}
summary(fit_brm2)
```

```{r}
#| label: tbl-brms-hurdle-model-summary-2
#| tbl-cap: Fixed/population-level effects for the non-zero part of the full lognormal hurdle glm.

fit_brm2 <- readRDS("fits/fit-brms-hurdle-lognormal-mi.rds")
smry2 <- summary(fit_brm2)
smry2$fixed$term <- rownames(smry2$fixed)
smry2$fixed |>
    select(term, Estimate, Est.Error, `l-95% CI`, `u-95% CI`) |>
    filter(
        stringr::str_sub(term, 1,2) != "hu"
    ) |>
    kableExtra::kable(format = "latex", digits = 2, escape = TRUE, row.names = FALSE,
                      col.names = c("Term", "Estimate", "SE", "LB 95% CI", "UB 95% CI"),
                      booktabs = TRUE)
```

```{r}
#| label: tbl-brms-hurdle-model-summary-2-zero
#| tbl-cap: Fixed/population-level effects for the zero part of the full lognormal hurdle glm.

smry2$fixed |>
    select(term, Estimate, Est.Error, `l-95% CI`, `u-95% CI`) |>
    filter(
        stringr::str_sub(term, 1,2) == "hu"
    ) |>
    kableExtra::kable(format = "latex", digits = 2, escape = TRUE,
                      col.names = c("Term", "Estimate", "SE", "LB 95% CI", "UB 95% CI"),
                      row.names = FALSE,
                      booktabs = TRUE)
```

The standard deviation parameter $\sigma$ of the lognormal distribution has a posterior mean of `r round(smry2$spec_pars[1,1], 2)` (95% CI: \[`r round(smry2$spec_pars[1,3], 2)`, `r round(smry2$spec_pars[1,4], 2)`\]).

The county-level random/group-level effects and year-level random/group-level effects are reported in @tbl-brms2-re.

```{r}
#| label: tbl-brms2-re
#| tbl-cap: Random/group-level effect standard deviation estimates for the full hurdle lognormal model.
r_effs2 <- bind_rows(smry2$random)
r_effs2$level <- c("County-level", "County-level", "Year-level")
r_effs2$term <- c("sd(Intercept)", "sd(hu_Intercept)", "sd(Intercept")
r_effs2 |>
    select(level, term, Estimate, `l-95% CI`, `u-95% CI`) |>
    kableExtra::kable(format = "latex", digits = 2, escape = TRUE,
                      col.names = c("Term", "Estimate", "SE", "LB 95% CI", "UB 95% CI"),
                      row.names = FALSE,
                      booktabs = TRUE)
```

```{r}
#| label: brms2-vars
#| include: false
smry2$spec_pars

smry2$random$COUNTY
smry2$random$YEAR
```

```{r}
#| label: fig-brm2-mcmc
#| fig-cap: MCMC plots for full lognormal hurdle model
#| fig-subcap: 
#|   - Age
#|   - Age Squared
#|   - Sex
#|   - Offender Race
#|   - OGS
#|   - OGS Squared
#|   - Prev. Rec.
#|   - Rec. Min. 
#|   - Crime Type
#|   - Trial
#|   - Race by Sex
#|   - OGS by Prev. Rec.
#| layout-ncol: 3
#| layout-nrow: 4
#| include: true
plot(fit_brm2, ask = FALSE, N = 3)
```

```{r}
#| label: fig-cond-eff-brm2-nonzero
#| layout-ncol: 3
#| layout-nrow: 4
#| fig-cap: Posterior estimates of the conditional effects for the lognormal glm for the non-zero-part of the full hurdle lognormal model.
#| fig-subcap: 
#|   - Age
#|   - Age Squared
#|   - Sex
#|   - Offender Race
#|   - OGS
#|   - OGS Squared
#|   - Prev. Rec.
#|   - Rec. Min. 
#|   - Crime Type
#|   - Trial
#|   - Race by Sex
#|   - OGS by Prev. Rec.
plot(conditional_effects(fit_brm2), ask = FALSE)
```

```{r}
#| label: fig-cond-eff-brm2
#| layout-ncol: 3
#| layout-nrow: 4
#| fig-cap: Posterior estimates of the conditional effects for the logistic regression on the zero-part of the full hurdle lognormal model.
#| fig-subcap:
#|   - Age
#|   - Age Squared
#|   - Sex
#|   - Offender Race
#|   - OGS
#|   - OGS Squared
#|   - Prev. Rec.
#|   - Rec. Min. 
#|   - Crime Type
#|   - Trial
#|   - Race by Sex
#|   - OGS by Prev. Rec.
plot(conditional_effects(fit_brm2, dpar = "hu"), ask = FALSE)
```

```{r}
#| label: fig-ppc-brm2
#| fig-cap: Posterior Predictive Checks for the full lognormal hurdle model.
#| fig-subcap: 
#|   - PPC Density Sentence Length (days)
#|   - PPC Density Log of Sentence Length plus 1
#|   - PPC Scatter of average error by age
#| layout-ncol: 3
ppred2 <- posterior_predict(fit_brm2)
pp_check(fit_brm2, ndraws = 50) +
    coord_cartesian(xlim = c(0, 60*30)) + 
    labs(title = "Posterior predictive checks",
                  subtitle = "Linear Predictor Hurdle",
         x = "Sentence Length (mon)")

bayesplot::ppc_dens_overlay(y = log1p(fit_brm2$data$JP_MIN),
                            yrep = log1p(ppred2[1:50,])) + 
    labs(title = "Posterior predictive checks",
                  subtitle = "Linear Predictor Hurdle",
         x = "log(Sentence Length (mon))")

bayesplot::ppc_error_scatter_avg_vs_x(y = log1p(fit_brm2$data$JP_MIN),
                            yrep = log1p(ppred2[1:50,]),
                            x = fit_brm2$data$DOSAGE) + 
    labs(title = "Posterior predictive checks",
                  subtitle = "Linear Predictor Hurdle",
         x = "log(Sentence Length (mon))")
```

#### GLMMadaptive Lognormal Hurdle Model

Complete case analysis to see if the function works and how quickly it runs.

```{r}
#| label: fit-glmmadaptive-lognormal-hurdle
#| eval: false

# DOSAGE + SEX + OFF_RACE + OGS + PRVREC + RECMIN + CRIME + TRIAL

fit_lnh <- mixed_model(JP_MIN ~ DOSAGE + SEX + OFF_RACE + OGS + PRVREC + RECMIN + CRIME + TRIAL,
                    random = ~ 1 | YEAR,
                    zi_fixed = ~ DOSAGE + DOSAGEQ + SEX * OFF_RACE + RECMIN + OGS + OGSQ + PRVREC + CRIME + TRIAL,
                    zi_random = ~ 1 | YEAR,
                    data = df[s,],
                    family = hurdle.lognormal(),
                    penalized = TRUE,
                    iter_EM = 0)

saveRDS(fit_lnh, "fits/fit-glmmadaptive-lognormal-hurdle.rds")
```

```{r}
#| label: load-glmmadaptive-lognormal-hurdle
fit_lnh <- readRDS("fits/fit-glmmadaptive-lognormal-hurdle.rds")

# fit_lnh
# marginal_coefs(fit_lnh)

# ses <- diag(fit_lnh$Hessian) |> sqrt() 
# 
# cbind(c(fit_lnh$coefficients, fit_lnh$gammas), ses) |> round(2)
```

Evaluation of predictions

```{r}
#| label: fig-cdf-glmm-lnh-pred
#| fig-cap: The empirical CDF of the observed sentence lengths (days, log scale) with fitted cdfs simulated from the model fit overlaid in light gray.
par(mar = c(2.5, 2.5, 0, 0), mgp = c(1.1, 0.5, 0), cex.axis = 0.7, cex.lab = 0.8)
y <- df$JP_MIN
y <- y[which(!is.na(y))]
y[y > 0] <- log(y[y > 0])
x_vals <- seq(min(y)-1, max(y), length.out = 500)
out <- simulate(fit_lnh, nsim = 30, acount_MLEs_var = FALSE)
ind <- out > sqrt(.Machine$double.eps)
out[ind] <- log(out[ind])
rep_y <- apply(out, 2, function (x, x_vals) ecdf(x)(x_vals), x_vals = x_vals)
matplot(x_vals, rep_y, type = "l", lty = 1, col = "lightgrey", 
        xlab = "Response Variable", ylab = "Empirical CDF")
lines(x_vals, ecdf(y)(x_vals))
legend("bottomright", c("log replicated data", "log observed data"), lty = 1, 
       col = c("lightgrey", "black"), bty = "n", cex = 0.8)
```

Fitting with MI.

```{r}
#| label: fit-glmmadaptive-lognormal-hurdle-mi
#| eval: false

start <- Sys.time()
imp_list <- complete(imps, "all", include = FALSE)


fit_lnh_mi <- lapply(imp_list, function(imp) {
    fit_lnh <- mixed_model(JP_MIN ~ DOSAGE + DOSAGEQ + SEX * OFF_RACE + OGS *  PRVREC +
                    OGSQ + RECMIN + CRIME + TRIAL,
                    random = ~ 1 | YEAR,
                    zi_fixed = ~ DOSAGE + DOSAGEQ + SEX * OFF_RACE + RECMIN + OGS + OGSQ + PRVREC + CRIME + TRIAL,
                    # zi_random = ~ 1 | YEAR,
                    data = imp,
                    family = hurdle.lognormal(),
                    penalized = TRUE,
                    optimizer = "nlminb")
    return(fit_lnh)
})

print(Sys.time() - start)
saveRDS(fit_lnh_mi, "fits/fit-glmmadaptive-lognormal-hurdle-mi.rds")
```

```{r}
#| label: tbl-coef-comp
#| tbl-cap: Coefficients from the non-zero portions of the full lognormal hurdle models fit with brms and glmmadaptive after multiple imputation.

fit_lnh_mi <- readRDS("fits/fit-glmmadaptive-lognormal-hurdle-mi.rds")

est_lnh_mi <- lapply(fit_lnh_mi, function(fit) {fit$coefficients}) |> bind_rows() |> apply(2, mean)

hu_lnh_mi <- lapply(fit_lnh_mi, function(fit) {fit$gammas}) |> bind_rows() |> apply(2, mean)

coef_est <- smry2$fixed |>
    filter(stringr::str_sub(term, 1, 2) != "hu") |>
    select(term, Estimate)
hu_est <- smry2$fixed |>
    filter(stringr::str_sub(term, 1, 2) == "hu") |>
    mutate(
        term2 = stringr::str_sub(term, 4, -1)
    ) |>
    select(term2, Estimate)

coef_est$glmmadapt <- est_lnh_mi
hu_est$glmmadapt <- hu_lnh_mi

coef_est2 <- left_join(coef_est, hu_est,
                      by = c("term" = "term2"), suffix = c("_nz", "_hu"))

coef_est2 |> 
    select(term, Estimate_nz, glmmadapt_nz, Estimate_hu, glmmadapt_hu) |>
    kableExtra::kable(format = "latex", digits = 4, escape = TRUE,
                      col.names = c("Term", "brms - Est.", "glmma - Est.",
                                    "brms - Hurdle Est.", "glmma - Hurdle Est."),
                      row.names = FALSE,
                      booktabs = TRUE)
```

## Sensitivity Analysis

Evaluating the impacts of various nonignorable missingness mechanisms can be accomplished with pattern-mixture models. The values of the incomplete numeric data can be scaled or shifted. The same cannot be done with categorical imputations, instead the proportion of each category can be varied within the imputations compared to the observed distribution or the MAR imputed distribution.

While there are very few missing sentence lengths, I could also modify the imputed sentence lengths with a scale $c$ or shift $\delta$. Scaling maintains that offenders that are non-incarcerated will remain non-incarcerated while the sentences of incarcerated defenders would shift. A positive shift would make all offenders incarcerated while a negative shift would impose negative sentence lengths that would need to be corrected to use Poisson or lognormal hurdle glms.

```{r}
#| label: rf-fit
#| include: false
c_dat_s <- na.exclude(df[s,])

fit_rf <- ranger::ranger(OFF_RACE ~ DOSAGE + DOSAGEQ + SEX + TRIAL + RECMIN + PRVREC + OGS + OGSQ + CRIME + YEAR + COUNTY + JP_MIN, 
                         data = c_dat_s,
                         probability = TRUE)

print(fit_rf)

fit_rf$confusion.matrix
```

```{r}
#| label: rf-pred

sample_rf_pd <- function(dat, fit, scale = c(1, 1, 1, 1)) {
    pred_rf <- predict(fit, data = dat)
    ppred_rf <- pred_rf$predictions
    
    plab <- unlist(lapply(1:nrow(dat), function(i) {
        p_i <- ppred_rf[i,]
        p_i <- p_i * scale
        p_i <- 1/sum(p_i) * p_i
        sample(colnames(ppred_rf), size = 1, prob = p_i)
        }))
}
```

To perturb the imputations, we modify the vector of probabilities $\mathbf{p} = (p_1, p_2, p_3, p_4)'$ of class membership for each racial/ethnic group under consideration (White, Black, Latino, or Other). A vector of scale parameters $\mathbf{c} = (c_1, c_2, c_3, c_4)'$ is chosen such that the new racial/ethnic group label will be drawn from the normalized vector $\mathbf{p}^* = \frac{1}{\sum_{j=1}^4 c_j p_j} (c_1 p_1, c_2 p_2, c_3 p_3, c_4 p_4)'$ so that the probability vectors remains the same if $c_j = 1$ for each $j = 1,\dots,4.$ For simplicity, we will focus on varying the probability of assigning a White label by changing only $c_1$ while holding $c_2 = c_3 = c_4 = 1.$

The vector of probabilities $\mathbf{p}_i$ is obtained for each incomplete observation $i$ by re-fitting the same random forest used in the initial mulitple imputation step. This vector is then scaled and normalized using the same scaling vector $\mathbf{c}$ for all incomplete observations. The probability vectors $\mathbf{p}^*$ are used to draw new imputed racial/ethnic group labels for the incomplete observations. This procedure is repeated, including the model fitting, across each of the $M$ completed data sets resulting in a new set of $M$ completed data sets with modified imputations. The new set of completed data sets is then analyzed as before using an lognormal hurdle model. Estimates from each variation of $\mathbf{c}$ that is chosen are then compared graphically in @fig-sens-analysis-res.

We choose to vary $c_1$ along the sequence $\{0.1, 0.33, 0.75, 0.9, 1, 1.1, 1.25, 1.5, 2\}.$ When $c_1 = 1$, the imputations correspond to the original imputation model under the MAR assumption. For $c_1 < 1$, fewer observations are imputed with a White label than under the MAR assumption reflecting a more diverse population of offenders who have unknown or unreported race labels. The opposite is true for $c_1 > 1$, reflecting a more White population of offenders. We include cases such as $c_1 = 0.1$ and $c_1 = 0.33$ as well as $c_1 = 1.5$ and $c_1 = 2$ as rather implausible extreme conditions to investigate what could happen in the most extreme circumstances.

```{r}
#| label: fn-modify-imps

modify_race_imps <- function(imps, scale = c(1.5, 1, 1, 1)) {
    
    mis_ind <- which(is.na(df[s,"OFF_RACE"]))
    
    imp_list2 <- lapply(1:length(imp_list), function(i) {
        df <- imp_list[[i]]
        
        if (sum(is.na(df)) == 0) {
            fit_imp <- ranger::ranger(OFF_RACE ~ DOSAGE + DOSAGEQ + SEX + TRIAL +
                                          RECMIN + PRVREC + OGS + OGSQ + CRIME +
                                          YEAR + COUNTY + JP_MIN, 
                                 data = df[-mis_ind,],
                                 probability = TRUE)
            new_imp <- sample_rf_pd(df[mis_ind,], fit_imp, scale = scale)
            df[mis_ind, "OFF_RACE"] <- new_imp
        }
        
        df$.imp <- i-1
        df$.id <- 1:nrow(df)
        
        return(df)
    })
    
    imps2 <- imp_list2 |>
        bind_rows() |>
        as.mids()
    return(imps2)
}

```

```{r}
#| label: sensitivity-analysis
#| eval: false
# sens_scales <- c(0.1, 0.33, 0.75, 0.9, 1, 1.1, 1.25, 1.5, 2)
sens_scales <- c(0.9, 0.95, 0.975, 1, 1.025, 1.05, 1.1)

sens_res <- lapply(sens_scales, function(s) {
    
    if (s != 1) {
        scale <- c(s, 1, 1, 1)
        imps2 <- modify_race_imps(imps, scale = scale)
    }
    else {
        imps2 <- imps
    }
    
    imp_list <- complete(imps2, "all", include = FALSE)
    
    fit_lnh_mi <- lapply(imp_list, function(imp) {
        fit_lnh <- mixed_model(JP_MIN ~ DOSAGE + DOSAGEQ + SEX + OFF_RACE + OGS + OGSQ +
                        OGS * PRVREC + PRVREC + RECMIN + CRIME + TRIAL,
                        data = imp,
                        family = hurdle.lognormal(),
                        random = ~ 1 |COUNTY,
                        zi_fixed = ~ DOSAGE + DOSAGEQ + SEX + OFF_RACE + OGS + OGSQ + PRVREC + RECMIN + CRIME + TRIAL,
                        # zi_random = ~ 1 | COUNTY
                        )
        return(fit_lnh)
    })
    
    # fit <- with(imps2, glm(INCAR ~ DOSAGE + DOSAGEQ + SEX*OFF_RACE + OGS + OGSQ +
    #                   OGS * PRVREC + PRVREC + RECMIN + CRIME + TRIAL +
    #                  as.factor(YEAR) + as.factor(COUNTY),
    #              family = binomial(link = "logit"),
    #              x = FALSE, y = FALSE,
    #              model = FALSE))
    
    # smry <- summary(pool(fit))
    # 
    # smry |>
    #     filter(stringr::str_sub(term, 1,3) != "as.") |>
    #     mutate(
    #         lb95 = estimate - qt(0.975, df = df) * std.error,
    #         ub95 = estimate + qt(0.975, df = df) * std.error,
    #         sig = case_when(
    #             lb95 > 0 ~ "*",
    #             ub95 < 0 ~ "*",
    #             TRUE ~ ""
    #         ),
    #         scale = s
    #     ) |>
    #     select(term, estimate, std.error, lb95, ub95, sig, scale)
    est_lnh_mi <- lapply(fit_lnh_mi, function(fit) {fit$coefficients}) |> 
        bind_rows() |>
        apply(2, mean)
    
    hu_lnh_mi <- lapply(fit_lnh_mi, function(fit) {fit$gammas}) |> 
        bind_rows() |> 
        apply(2, mean)
    
    res <- bind_rows(est_lnh_mi, hu_lnh_mi)
    res$mod <- c("lognormal", "logistic")
    res$scale <- s
    return(res)
})

# str(sens_res)

saveRDS(sens_res, "fits/sensitivity-analysis-results.rds")
```

```{r}
#| label: fig-sens-analysis-res
#| fig-cap: Coefficient estimates for the logistic regression model predicting incarceration.


# sens_scales <- c(0.1, 0.33, 0.75, 0.9, 1, 1.1, 1.25, 1.5, 2)
# sens_scales <- c(0.33, 0.75, 0.9, 1, 1.1, 1.25, 1.67)

sens_res <- readRDS("fits/sensitivity-analysis-results.rds")

# sens_res |>
#     bind_rows() |>
#     filter(term %in% c("OFF_RACEBLACK")) |>
#     ggplot(aes(scale, estimate, color = as.factor(scale))) +
#         geom_point() +
#         scale_color_viridis_d(name = "Scale Factor")

sens_res2 <- sens_res |> bind_rows()

# sens_res2$scale <- rep(sens_scales, each = 2)

sens_res2 |>
    tidyr::pivot_longer(cols = `(Intercept)`:`OGS:PRVRECREVOC/RFEL`,
                        names_to = "term",
                        values_to = "estimate") |>
    filter(term == "OFF_RACEBLACK") |>
    ggplot(aes(scale, estimate)) +
        geom_point(aes(color = as.factor(scale), shape = mod)) +
        scale_color_viridis_d(name = "Scale Factor") +
        geom_line(aes(linetype = mod))
```

\newpage

## References {.unnumbered}

::: ref
:::
